<!doctype html>
<html >
  <head>
    <meta charset="utf-8">
    <title>Parameter Estimation</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link type="application/atom+xml" rel="alternate" href="http://emkayoh.com/feed.xml" />
    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Parameter Estimation</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Parameter Estimation" />
<meta name="author" content="academia" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://emkayoh.com/2021/04/05/parameter-estimation.html" />
<meta property="og:url" content="http://emkayoh.com/2021/04/05/parameter-estimation.html" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-04-05T00:00:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Parameter Estimation" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"http://emkayoh.com/2021/04/05/parameter-estimation.html"},"url":"http://emkayoh.com/2021/04/05/parameter-estimation.html","author":{"@type":"Person","name":"academia"},"dateModified":"2021-04-05T00:00:00+01:00","datePublished":"2021-04-05T00:00:00+01:00","headline":"Parameter Estimation","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <div class="wrapper" >  
        <header class="main-head">
           <a href="\">
               <h1 class="headerText">Dr Jeremiah Kelly</h1>
           </a>
        </header>

        <article class="content"style="padding-left:1em;">

<h2>Parameter Estimation</h2>

<p>
  05 Apr 2021
  
  
    - <a href="/authors/academia.html">Academia</a>
  
</p>

<style type="text/css">
code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
</style>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
    },
    TeX: { 
        Macros:{
            fn: "Residuals"
        },
        extensions: ["AMSmath.js","autobold.js"]},
});
MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_HTML-full"></script>

<h2 id="dark-adaptation-models">Dark adaptation models</h2>

<p>There are at least two models used in the literature.
The first is a twin exponential decay</p>
<div>
<img src="/assets/images/CI_fig_01" alt="drawing" width="600" />
</div>
<p>the second, an exponential, bilinear model, is more complex and was first described by Mahroo and Lamb (ref)</p>
<div>
<img src="/assets/images/CI_fig_02" alt="drawing" width="600" />
</div>
<p>We are concerned with a reduced form of the Mahroo and Lamb Model with only five parameters.The threshold $Thr~(log(cd.m^{-2})$) with respect to $time~(minutes)$ of adaptation is defined as the sum of the Cone response; <br /></p>
<div style="align:center;">$$Thrs_{cone} = CT + CC*\exp{(\dfrac{-time}{\tau})},$$ </div>

<p>where $CT$ is the absolute cone threshold ($log(cd.m^{-2})$), $CC~(log(cd.m^{-2})$) the cone offset at time zero, and the time constant of recovery $\tau~(minutes)$,  and the Rod threshold;
<br /></p>
<div style="align:center;">$$Thrs_{rod} = \dfrac{S2 *(time-\alpha)}{1 + \exp{(-k*(time - \alpha))}},$$ </div>

<p>where $S2~(log(cd.m^{-2}).min^{-1})$ is the rate limited rod recovery rate, $\alpha~(min)$ is the time when rod sensitivity is greater than cone sensitivity, and $k$ is a dimensionless value. The denominator ensures that rod contribution to sensitivity is nil before $\alpha$ and additive after, the value of $k$ affects the rate of switch transition and is discussed in the appendix.</p>
<div>
<img src="/assets/images/CI_fig_03" alt="drawing" width="600" />
</div>

<p>Hence the estimated threshold for a time $t$ and model parameter estimate $\boldsymbol{\hat\theta}$ is; 
\begin{equation}\label{eqn:est}
\tag{1}
Thrs(\boldsymbol{\hat\theta}, t) = \theta_1 + \theta_2\exp\Big({\dfrac{-t}{\theta_3}} \Big) +  \theta_4\dfrac{(t-\theta_5)}{1 + \exp{(-k*(t - \theta_5)})}\end{equation}</p>

<p>and it follows that the residuals can be written as a vector $\bf{R}$  where</p>

<p>\begin{align}\label{eqh:resi}
          \boldsymbol{R(\hat\theta)} &amp;= \begin{bmatrix} 
          thrs_1 - Thrs(\boldsymbol{\hat\theta}, time_1) \cr
          thrs_2 - Thrs(\boldsymbol{\hat\theta}, time_2) \cr
          thrs_3 - Thrs(\boldsymbol{\hat\theta}, time_3) \cr
          \vdots<br />
          thrs_n - Thrs(\boldsymbol{\hat\theta}, time_n)
         \end{bmatrix}
\end{align}</p>

<h2 id="finding-the-parameters">Finding the parameters</h2>

<p>We are interested in the parameters ($\boldsymbol{\theta}$) of the model described above, a common technique takes a number ($n$) of threshold measurements over time and calculates the difference between the actual measurements and estimated values for a given set of parameters. These differences are squared and summed, then the parameters of the model are modified until the sum of squares is at a minimum, the final parameter values are then considered optimal. The sum of the squared differences of the measured threshold and the estimated threshold is minimised, such that when $L(\boldsymbol{\theta})$ is at a minimum, the values of $\theta$ are the best estimate.</p>

<p>This objective function can be written using $\odot$ to express element wise multiplication
\(L(\boldsymbol{\hat\theta}) = \sum_{i = 1}^{n}{\boldsymbol{R(\hat\theta)}\odot \boldsymbol{R(\hat\theta)}}.\) We use element wise multiplication notation to retain the $\sum$ notation.</p>

<p>When $L(\boldsymbol{\hat\theta})$ is at a minimum, $\dfrac{dL}{d\boldsymbol\theta} = 0$. We can use the gradient of the slope of the objective function to locate the minimum of the function using a gradient descent method.</p>

<h3 id="gradient-decent">Gradient decent</h3>

<p>We assume the objective function is convex over the parameter space, so that we can use the partial derivatives of the objective function to estimate the values of $\boldsymbol{\theta}$. A function composed of non decreasing convex functions will be convex, see a<a href="https://math.stackexchange.com/questions/108393/s-the-composition-of-n-convex-functions-itself-a-convex-function, 11/11/2020">possible weakness here.</a></p>

<p>The method is illustrated in the figure below, and is briefly as follows. The gradient of the objective function for a set of parameters values (location 1), summarised as $\boldsymbol{\hat\theta}_1$ is found, these values are used to make a further estimate $\boldsymbol{\hat\theta}_2$ and a new gradient is found, which in turn is used to estimate new parameter values. The process is repeated until further changes yield little or no improvement in the value of $L(\boldsymbol{\hat\theta}_n)$.</p>

<div>
<img src="/assets/images/CI_fig_04" alt="drawing" width="600" />
</div>

<h3 id="finding-the-gradient-vector">Finding the gradient vector</h3>

<p>This all builds into a gradient vector that is used to move from the initial estimate to the next.</p>

<p>then the differentials can be expressed as;</p>

<p>\begin{align}
\frac{\partial L}{\partial\theta_1} &amp;= -2\sum_{i = 1}^{n}\Big( \boldsymbol{R}(\hat\theta)\odot \boldsymbol{1} \Big), \cr
\qquad &amp;\textrm{[cone threshold]}\cr
\frac{\partial L}{\partial\theta_2} &amp;= -2\sum_{i = 1}{n}\Big( \boldsymbol{R}(\hat\theta)\odot \exp\Big(-\dfrac{time_i}{\theta_3}  \Big)\Big),\cr
\qquad &amp;\textrm{[cone offset]}\cr
\frac{\partial L}{\partial\theta_3} &amp;= -2\sum_{i = 1}{n}\Big( \boldsymbol{R}(\hat\theta)\odot \dfrac{\exp\Big(-\theta_2.\dfrac{time_i}{\theta_3}.time_i  \Big) }{\theta_3^2}\Big),\cr
\qquad &amp;\textrm{[cone time constant]}\cr
\frac{\partial L}{\partial\theta_4} &amp;= -2\sum_{i = 1}^{n}\Big( \boldsymbol{R}(\hat\theta)\odot \dfrac{(time_i - \theta_5)}{\big(1 + \exp(time_i - \theta_5)  \big) }\Big), \cr
\qquad &amp;\textrm{[S2, rod rate of recovery]}\cr
\frac{\partial L}{\partial\theta_5} &amp;= -2\sum_{i = 1}^{n}\Big( \boldsymbol{R}(\hat\theta)\odot \Big(\dfrac{\theta_4}{1+\exp(time_i - \theta_5)}- \theta_4. \exp(time_i - \theta_5)\dfrac{(time_i - \theta_5)}{(1 + \exp(time_i - \theta_5))^2}  \Big)\Big). \cr
\qquad &amp;\textrm{[cone-rod break point]}\cr
\end{align}</p>

<p>hence <br />
\begin{align}
    \nabla_\theta \boldsymbol{L(\theta)} &amp;= \begin{bmatrix}
          \frac{\partial L}{\partial\theta_1} \cr
           \frac{\partial L}{\partial\theta_2}\cr
           \frac{\partial L}{\partial\theta_3}\cr
           \frac{\partial L}{\partial\theta_4} \cr
           \frac{\partial L}{\partial\theta_5}
         \end{bmatrix}
  \end{align}</p>

<p>Having found the gradient vector then we do the descent thing</p>

<h3 id="plain-gradient-descent">Plain gradient descent</h3>

<p>\begin{equation}\label{eqn:vani}
\hat\theta_{n+1} =\hat\theta_{n} - \eta\nabla_\theta L(\hat\theta_{n}) <br />
\end{equation}</p>

<h3 id="momentum">Momentum</h3>

<p>\begin{equation} 
v_0 = \boldsymbol{0}
\end{equation}</p>

<p>\begin{equation} 
v_n = \gamma v_{n-1} + \eta \nabla_\theta L(\hat\theta_{n})
\end{equation}
\begin{equation} 
\hat\theta_{n+1} = \hat\theta_{n} - v_n 
\end{equation}</p>

<h3 id="nesterov">Nesterov</h3>

<p>\begin{equation} 
v_n = \gamma v_{n-1} + \eta \nabla_\theta L( \hat\theta_{n} - \gamma v_{n-1} )
\end{equation}
\begin{equation} 
\hat\theta_{n+1} = \hat\theta_{n} - v_n 
\end{equation}</p>

<h2 id="how-do-the-gradient-values-vary-as-the-estimate-changes">How do the gradient values vary as the estimate changes?</h2>

<p>The first order partial differential equations are plotted below.</p>

<p>The parameters ct, cc and S2 are linear in the model</p>

<div>
<img src="/assets/images/CI_fig_05" alt="drawing" width="800" />
</div>
<p>However the cone rod break time (alpha) behaves quite differently, notice that if the initial estimates for alpha and tau are greater than 12 or 6 respectively then the gradient function will direct the parameter search in the ‘wrong’ direction.</p>
<div>
<img src="/assets/images/CI_fig_06" alt="drawing" width="800" />
</div>
<div>
<img src="/assets/images/CI_fig_07" alt="drawing" width="800" />
</div>

<h2 id="appendix">Appendix</h2>

<p>\begin{equation}
\boldsymbol{\nabla(\theta)} = 
\end{equation}</p>

<p>\begin{equation}\label{eqn:ct}
\frac{\partial L}{\partial\theta_1} =
\frac{\partial L}{\partial CT} = 
-2\sum_{i =1}^{n}{\fn{}}
\end{equation}</p>

<p>\begin{equation}\label{eqn:cc}
\frac{\partial L}{\partial\theta_2} =
\frac{\partial L}{\partial CC} = 
-2 \sum_{i =1}^{n}\exp\Big(-\dfrac{time_i}{\theta_3}  \Big).{\fn{}}
\end{equation}</p>

<p>\begin{equation}\label{eqn:tau}
\frac{\partial L}{\partial\theta_3} =
\frac{\partial L}{\partial \tau} = 
-2\sum_{i =1}^{n}\dfrac{\exp\Big(-\dfrac{time_i}{\theta_3}\Big)\theta_2.time_i   {.\fn{}}}{\theta_3^2}
\end{equation}</p>

<p>\begin{equation}\label{eqn:s2}
\frac{\partial L}{\partial\theta_4} =
\frac{\partial L}{\partial{S2}} = 
-2\sum_{i =1}^{n}\dfrac{(time_i - \theta_5){.\fn{}}}{\big(1 + \exp(time_i - \theta_5)  \big)}
\end{equation}</p>

<p>\begin{equation}
\frac{\partial L}{\partial\theta_5} =
\frac{\partial L}{\partial \alpha} = 
 2\sum_{i =1}^{n}\Big(\dfrac{\theta_4}{1+\exp(time_i - \theta_5)}- \theta_4. \exp(time_i - \theta_5)\dfrac{(time_i - \theta_5)}{(1 + \exp(time_i - \theta_5))^2}  \Big)<br />
 <br />
 {.\fn{}}
\end{equation}</p>





</article> 

        <aside class="side">
<nav class="nav-bar">
  
  <ul>
    <li> <img class="portrait"  src="/assets/images/Jeremiah.png">
  </li>
  
    <li><h3><a href="/" >Home</a></h3>
  </li>
    <li><h3><a href="/projects.html" >Projects</a></h3>
  </li>
    <li><h3><a href="/blog.html" >Notes</a></h3>
  </li>
    <li><h3><a href="https://emkayoh.github.io/online-cv" >CV</a></h3>
  </li>
  </ul>
</nav>

        </aside>

        <div class="credit">
              <a href="#" class="fa fa-github"></a>
<a href="#" class="fa fa-twitter"></a>
          <a href="#" class="fa fa-linkedin"></a>
<a href="#" class="fa fa-youtube"></a>
            <a href = "http://www.emkayoh.com">  &copy;  Emkayoh Consulting Ltd </a> 2020
        </div>

        <footer class="main-footer">
            Company Number 

        </footer>

    </div>
  </body>


</html>
